{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G202158002 Shin Won Hyung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 5.1\n",
    "\n",
    "$P(w | \\theta) = \\frac{1}{\\theta} \\exp(-\\frac{1}{\\theta}w)$\n",
    "\n",
    "$\\Rightarrow W = W(\\theta) ~ \\sim ~ Exp(\\frac{1}{\\theta})$\n",
    "\n",
    "Let $W' ~ \\sim ~ Exp(1)$, then $Q(\\theta, V)$ is expressed in the equicalent form\n",
    "\n",
    "$$Q(\\theta, V) = f(\\theta, Z) + \\frac{1}{\\theta} W'$$\n",
    "\n",
    "and joint distribution for $\\{Z, W'\\}$ does not depend on $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 5.4\n",
    "\n",
    "Let $Q(\\theta, V)$ is noisy observation of $L(\\theta)$.\n",
    "\n",
    "Then,\n",
    "\n",
    "$$e(\\theta) = Q(\\theta, V) - L(\\theta) = \\theta^T W \\theta + \\theta^T w$$\n",
    "\n",
    "By condition A.3 of statistics conditions for convergence,\n",
    "\n",
    "$$E[e(\\theta)] = 0$$\n",
    "\n",
    "If $e(\\theta) ~ \\sim ~ N(0,1)$, then $E[e(\\theta)] = 0$.\n",
    "\n",
    "$$\\theta^T W \\theta + \\theta^T w = \\theta^T (W \\theta + w)$$\n",
    "\n",
    "Therefore, $W\\theta + w ~ \\sim ~ N(0, I_p)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 5.5\n",
    "\n",
    "$$Q(\\theta, V) = \\sum_{i=1}^{p/2} t_i + \\theta^T B \\theta + \\theta^T V$$\n",
    "\n",
    "$$\\frac{\\partial Q(\\theta, V)}{\\partial \\theta} = (B + B^T) \\theta + \\theta = (2B + I_p)\\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 5.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Case (i) / Replication 1] theta = [1.99178932 0.67422034]\n",
      "[Case (i) / Replication 2] theta = [0.42632878 4.34593277]\n",
      "[Case (i) / Replication 3] theta = [-1.04199602  9.85206361]\n",
      "[Case (i) / Replication 4] theta = [0.30418348 7.13508892]\n",
      "[Case (i) / Replication 5] theta = [0.10929207 3.89262157]\n",
      "\n",
      "[Case (ii) / Replication 1] theta = [-5.44028019 28.40830444]\n",
      "[Case (ii) / Replication 2] theta = [1.18017766 1.8399834 ]\n",
      "[Case (ii) / Replication 3] theta = [1.97344876 4.56361152]\n",
      "[Case (ii) / Replication 4] theta = [-3.53318884 22.14324123]\n",
      "[Case (ii) / Replication 5] theta = [0.33448318 3.81143552]\n",
      "\n",
      "[Case (iii) / Replication 1] theta = [1.64024194 0.55366367]\n",
      "[Case (iii) / Replication 2] theta = [1.65650074 0.52887176]\n",
      "[Case (iii) / Replication 3] theta = [1.63403321 0.52254819]\n",
      "[Case (iii) / Replication 4] theta = [1.59656676 0.51038819]\n",
      "[Case (iii) / Replication 5] theta = [1.65923174 0.52017671]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_x_pairs(max_sample_num=1000):\n",
    "    c = np.random.randint(1, 11, size=max_sample_num)\n",
    "    w = np.random.randint(11, 111, size=max_sample_num)\n",
    "    return np.stack([w,c], 1)\n",
    "\n",
    "def init_theta():\n",
    "    return np.array([1., .5])\n",
    "\n",
    "\n",
    "def generate_gain_seq(iter, start_gain):\n",
    "    return start_gain / np.power(iter + 100, .501) \n",
    "\n",
    "\n",
    "def generate_noise_1():\n",
    "    return np.random.normal(0, 5**2)\n",
    "\n",
    "\n",
    "def compute_h(theta, x):\n",
    "    lmbd, beta = theta\n",
    "    w, c = x\n",
    "    return lmbd * np.power(c, beta) * np.power(w, 1-beta)\n",
    "\n",
    "\n",
    "def compute_euclidian(theta, optimal_theta):\n",
    "    return np.sqrt(np.sum(np.power(theta - optimal_theta, 2)))\n",
    "\n",
    "\n",
    "def compute_grad(theta, x):\n",
    "    lmbd, beta = theta\n",
    "    w, c = x\n",
    "    grad_lmbd = w * np.power(c / w, beta)\n",
    "    grad_beta = lmbd * w * np.power(c / w, beta) * np.log(c / w)\n",
    "    \n",
    "    return np.array([grad_lmbd, grad_beta])\n",
    "\n",
    "\n",
    "def update_theta(theta, gain_seq, grad, x, z):\n",
    "    h = compute_h(theta, x)\n",
    "    return theta - gain_seq * grad * (h - z)\n",
    "\n",
    "\n",
    "max_iter = 1000\n",
    "max_repl = 5\n",
    "optimal_theta = np.array([2.5, 0.7])\n",
    "\n",
    "x = generate_x_pairs()\n",
    "\n",
    "for seed in range(max_repl):\n",
    "    theta = init_theta()\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(x)\n",
    "    \n",
    "    for iter, x_sample in enumerate(x):\n",
    "        gain_seq = generate_gain_seq(iter+1, start_gain=0.00125)\n",
    "        noise = generate_noise_1()\n",
    "\n",
    "        z = compute_h(optimal_theta, x_sample) + noise\n",
    "        grad = compute_grad(theta, x_sample)\n",
    "\n",
    "        theta = update_theta(theta, gain_seq, grad, x_sample, z)\n",
    "    print(f\"[Case (i) / Replication {seed+1}] theta = {theta}\")\n",
    "\n",
    "print()\n",
    "\n",
    "for seed in range(max_repl):\n",
    "    theta = init_theta()\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(x)\n",
    "    x_sum = np.array([0,0])\n",
    "    z_sum = 0.\n",
    "    for iter, x_sample in enumerate(x):\n",
    "        gain_seq = generate_gain_seq((iter+1) // 2, start_gain=0.0075)\n",
    "        noise = generate_noise_1()\n",
    "\n",
    "        z = compute_h(optimal_theta, x_sample) + noise\n",
    "        if (iter + 1) % 2 != 0:\n",
    "            x_sum += (x_sample)\n",
    "            z_sum += z\n",
    "            continue\n",
    "        \n",
    "        x_mean = x_sum / 2\n",
    "        z_mean = z_sum / 2\n",
    "        grad = compute_grad(theta, x_mean)\n",
    "\n",
    "        theta = update_theta(theta, gain_seq, grad, x_mean, z_mean)\n",
    "\n",
    "        x_sum = np.array([0,0])\n",
    "        z_sum = 0.\n",
    "    print(f\"[Case (ii) / Replication {seed+1}] theta = {theta}\")\n",
    "\n",
    "print()\n",
    "\n",
    "for seed in range(max_repl):\n",
    "    theta = init_theta()\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(x)\n",
    "    for epoch in range(10):\n",
    "        for iter, x_sample in enumerate(x):\n",
    "            gain_seq = generate_gain_seq(epoch*1000 + iter+1, start_gain=0.00015)\n",
    "            noise = generate_noise_1()\n",
    "\n",
    "            z = compute_h(optimal_theta, x_sample) + noise\n",
    "            grad = compute_grad(theta, x_sample)\n",
    "\n",
    "            theta = update_theta(theta, gain_seq, grad, x_sample, z)\n",
    "    print(f\"[Case (iii) / Replication {seed+1}] theta = {theta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
